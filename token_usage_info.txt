# Token Usage Tracking
# Started: 2026-02-17

## Test Results: Sonnet vs Haiku (2026-02-17)

### Task: Summarize MissionControl README in one sentence
Identical task, run twice each model for consistency.

| Run          | Model  | Total Tokens | In  | Out | Runtime |
|--------------|--------|-------------|-----|-----|---------|
| test-haiku   | Haiku  | 12,900      | 70  | 742 | 10s     |
| test-sonnet  | Sonnet | 10,000      | 5   | 250 | 14s     |
| token-test-haiku  | Haiku  | 12,500 | 36  | 448 | 7s  |
| token-test-sonnet | Sonnet | 11,700 | 5   | 274 | 9s  |

### Averages
- Haiku:  ~12,700 tokens avg | ~8.5s avg
- Sonnet: ~10,850 tokens avg | ~11.5s avg

### Key Findings
- Sonnet uses ~15% FEWER tokens than Haiku on summarization tasks
- Haiku is ~2-3s faster but generates significantly more output tokens
- Sonnet produces more concise, higher-quality output
- For heartbeat checks (short, focused tasks): Sonnet is better value

### Decision
- Switched default model to Sonnet, fallback to Haiku (2026-02-17)

---
## Ongoing Tracking

| Date | Task | Model | Tokens | Notes |
|------|------|-------|--------|-------|
| 2026-02-17 | README summary test | Haiku avg | 12,700 | baseline |
| 2026-02-17 | README summary test | Sonnet avg | 10,850 | baseline |
